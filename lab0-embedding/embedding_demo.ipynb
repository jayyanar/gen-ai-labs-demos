{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8500c1f4",
   "metadata": {},
   "source": [
    "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/jayyanar/gen-ai-labs-demos/blob/main/lab0-embedding/embedding_demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd00bf3-167d-43ee-a771-34d863ba0055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8e8f35-be17-49ef-bb82-540f7cd0ceb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "! pip install altair cohere pandas numpy vega --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4596779-dec7-4f99-88ee-ab48edaa192d",
   "metadata": {},
   "source": [
    "# Example Simple Word--quiet -- for Tokenize and apply Vectorizing using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b10bbab-48dc-4184-8f28-8eb958dddd58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tokenize\n\u001b[1;32m      4\u001b[0m \u001b[39m# Prepare a list of sentences (corpus)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "# Prepare a list of sentences (corpus)\n",
    "corpus = [\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"fruit\",\n",
    "    \"banana\"\n",
    "]\n",
    "\n",
    "# Preprocess the corpus by tokenizing the sentences\n",
    "tokenized_corpus = [list(tokenize(sentence)) for sentence in corpus]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get the vector representation of a word\n",
    "word = \"dog\"\n",
    "word_vector = model.wv[word]\n",
    "print(f\"Vector representation of '{word}':\\n{word_vector}\\n\")\n",
    "\n",
    "# Find similar words based on cosine similarity\n",
    "similar_words = model.wv.most_similar(word)\n",
    "print(f\"Similar words to '{word}':\")\n",
    "for sim_word, sim_score in similar_words:\n",
    "    print(f\"{sim_word}: {sim_score}\")\n",
    "\n",
    "# Check the vocabulary size\n",
    "vocabulary_size = len(model.wv)\n",
    "print(\"\\nVocabulary size:\", vocabulary_size)\n",
    "\n",
    "# Get the entire word vocabulary\n",
    "vocabulary = model.wv.key_to_index\n",
    "print(\"\\nWord Vocabulary:\")\n",
    "for word in vocabulary:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da890ac-ce42-4ba5-9a14-6417be91a93f",
   "metadata": {},
   "source": [
    "## Example Sentence - Tokenize and Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c34d3-8440-4c50-a1c4-005f1a167f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "# Prepare a list of sentences (corpus)\n",
    "corpus = [\n",
    "    \"I love playing football\",\n",
    "    \"Football is my favorite sport\",\n",
    "    \"I enjoy watching football matches\",\n",
    "    \"Soccer is popular worldwide\"\n",
    "]\n",
    "\n",
    "# Preprocess the corpus by tokenizing the sentences\n",
    "tokenized_corpus = [list(tokenize(sentence)) for sentence in corpus]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get the vector representation of a word\n",
    "word = \"football\"\n",
    "word_vector = model.wv[word]\n",
    "print(f\"Vector representation of '{word}':\\n{word_vector}\\n\")\n",
    "\n",
    "# Find similar words based on cosine similarity\n",
    "similar_words = model.wv.most_similar(word)\n",
    "print(f\"Similar words to '{word}':\")\n",
    "for sim_word, sim_score in similar_words:\n",
    "    print(f\"{sim_word}: {sim_score}\")\n",
    "\n",
    "# Check the vocabulary size\n",
    "vocabulary_size = len(model.wv)\n",
    "print(\"\\nVocabulary size:\", vocabulary_size)\n",
    "\n",
    "# Get the entire word vocabulary\n",
    "vocabulary = model.wv.key_to_index\n",
    "print(\"\\nWord Vocabulary:\")\n",
    "for word in vocabulary:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95e618-231b-49dc-a512-3044d4416c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere altair  --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22470f-0eb2-460f-bb6a-bd8562e232d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af1494-16a3-45de-8efd-bab89d133dc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Credential from Cred.json - Ref https://github.com/jayyanar/gen-ai-labs-demos/tree/main for Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938e4d5-d103-4fb9-a463-d575fce651b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "filepath = \"cred.json\"\n",
    "file = open(filepath, 'r')\n",
    "\n",
    "# Open the credentials file with json.load\n",
    "credentials = json.load(file)\n",
    "file.close()\n",
    "\n",
    "# Load API Key\n",
    "api_key = credentials['cohere_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e1e03-2ebf-45fa-bc98-7eb3c572b59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c734c-47bb-4183-b0f6-9fced61f7810",
   "metadata": {},
   "source": [
    "## Let us try with corpus of data from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378c3e2-8db3-41eb-8ae1-c8f2f2006378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset to a dataframe\n",
    "df_orig = pd.read_csv('https://raw.githubusercontent.com/cohere-ai/notebooks/main/notebooks/data/atis_intents_train.csv',names=['intent','query'])\n",
    "\n",
    "# Take a small sample for illustration purposes\n",
    "sample_classes = ['atis_airfare', 'atis_airline', 'atis_ground_service']\n",
    "df = df_orig.sample(frac=0.12, random_state=30)\n",
    "df = df[df.intent.isin(sample_classes)]\n",
    "df_orig = df_orig.drop(df.index)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Remove unnecessary column \n",
    "intents = df['intent'] #save for a later need\n",
    "df.drop(columns=['intent'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4b3b8-c76a-411e-8033-9680951e1d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get text embeddings\n",
    "def get_embeddings(texts,model='embed-english-v2.0'):\n",
    "  output = co.embed(\n",
    "                model=model,\n",
    "                texts=texts)\n",
    "  return output.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922a865-a676-45ac-87a5-b9075f6beec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Embed the dataset\n",
    "df['query_embeds'] = get_embeddings(df['query'].tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c598c-4c3e-4216-b37f-140963cd29ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce dimensionality using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Function to return the principal components\n",
    "def get_pc(arr,n):\n",
    "  pca = PCA(n_components=n)\n",
    "  embeds_transform = pca.fit_transform(arr)\n",
    "  return embeds_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090d256-b3c6-4fdc-9077-a9f7273638de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce embeddings to 10 principal components to aid visualization\n",
    "embeds = np.array(df['query_embeds'].tolist())\n",
    "embeds_pc = get_pc(embeds,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28882ae3-9d7e-496c-848b-0b507bd557c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between the search query and existing queries\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similarity(target,candidates):\n",
    "  # Turn list into array\n",
    "  candidates = np.array(candidates)\n",
    "  target = np.expand_dims(np.array(target),axis=0)\n",
    "\n",
    "  # Calculate cosine similarity\n",
    "  sim = cosine_similarity(target,candidates)\n",
    "  sim = np.squeeze(sim).tolist()\n",
    "  sort_index = np.argsort(sim)[::-1]\n",
    "  sort_score = [sim[i] for i in sort_index]\n",
    "  similarity_scores = zip(sort_index,sort_score)\n",
    "\n",
    "  # Return similarity scores\n",
    "  return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517eb46d-581e-489a-9558-33f668de145f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new query\n",
    "new_query = \"show business fares\"\n",
    "\n",
    "# Get embeddings of the new query\n",
    "new_query_embeds = get_embeddings([new_query])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1262f0a-7cf7-4a2a-81fa-555e627c7692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the similarity between the search query and existing queries\n",
    "similarity = get_similarity(new_query_embeds,embeds[:sample])\n",
    "\n",
    "# View the top 5 articles\n",
    "print('Query:')\n",
    "print(new_query,'\\n')\n",
    "\n",
    "print('Similar queries:')\n",
    "for idx,sim in similarity:\n",
    "  print(f'Similarity: {sim:.2f};',df.iloc[idx]['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa534d-6dcf-4f04-ab70-3e87d455af08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new dataframe and append new query\n",
    "df_sem = df.copy()\n",
    "df_sem.loc[len(df_sem.index)] = [new_query, new_query_embeds]\n",
    "\n",
    "# Reduce embeddings dimension to 2\n",
    "embeds_sem = np.array(df_sem['query_embeds'].tolist())\n",
    "embeds_sem_pc2 = get_pc(embeds_sem,2)\n",
    "\n",
    "# Add the principal components to dataframe\n",
    "df_sem_pc2 = pd.concat([df_sem, pd.DataFrame(embeds_sem_pc2)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96340b0d-457c-4737-afc4-1921d62edb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create column for representing chart legend\n",
    "df_sem_pc2['Source'] = 'Existing'\n",
    "df_sem_pc2.at[len(df_sem_pc2)-1, 'Source'] = \"New\"\n",
    "\n",
    "# Plot on a chart\n",
    "df_sem_pc2.columns = df_sem_pc2.columns.astype(str)\n",
    "selection = list(range(sample)) + [-1]\n",
    "generate_chart(df_sem_pc2.iloc[selection],'0','1',color='Source',title='Semantic Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839abf6b-d49e-481b-b3bc-48d45c0f0891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Pick the number of clusters\n",
    "df_clust = df_pc2.copy()\n",
    "n_clusters=2\n",
    "\n",
    "# Cluster the embeddings\n",
    "kmeans_model = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "classes = kmeans_model.fit_predict(embeds).tolist()\n",
    "df_clust['cluster'] = (list(map(str,classes)))\n",
    "\n",
    "# Plot on a chart\n",
    "df_clust.columns = df_clust.columns.astype(str)\n",
    "generate_chart(df_clust.iloc[:sample],'0','1',lbl='on',color='cluster',title='Clustering with 2 Clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567562de-7c8c-49b5-ac35-950a5ee2e0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
