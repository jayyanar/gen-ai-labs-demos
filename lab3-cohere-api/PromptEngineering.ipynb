{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d513a04-55ad-4cbb-bb86-81dea9c6b46c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prompt Engineering 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c17af9-8edc-450a-99a1-bac1c56172a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a file name cred.json in your local workspace with API Key\n",
    "\n",
    "e.g) \n",
    "\n",
    "{\n",
    "\"cohere_api_key\":\"idontshare\",\n",
    "\"dreamstudio_api_key\":\"idontshare\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3ec64-2d3a-4747-b57b-b7d193697592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install cohere --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df35231-d117-404a-98da-92e14fd4c34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "filepath = \"cred.json\"\n",
    "file = open(filepath, 'r')\n",
    "\n",
    "# Open the credentials file with json.load\n",
    "credentials = json.load(file)\n",
    "file.close()\n",
    "\n",
    "# Load API Key\n",
    "api_key = credentials['cohere_api_key']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbc74e-654a-4684-a11b-a031734964e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prompting - 101 - Content Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e8e3b-a564-484b-8f3e-2383dffb42fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the content\n",
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Write a LinkedIn post about starting a career in tech:',\n",
    "  max_tokens=800,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ca0cf-4924-4aca-9cd0-49fa18c818c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Temperature to Generate more questions\n",
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Generate a list of 5 interview questions for a AWS DevOps Engineer',\n",
    "  max_tokens=500,\n",
    "  temperature=0.5,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7372a-317c-4534-a671-b355d30a94b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prompt Engineering - Zero-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b5696-a18b-489a-b076-2843850b60ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Translate from English to French\n",
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Translate English to French \\\"I love AWS User Group Bangalore. All the technical topic provided by them are insightful and make positive impacts\\\"',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ff2ad-c2d5-40a6-86ed-6dea299723be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize the Text\n",
    "import cohere\n",
    "co = cohere.Client(api_key)# This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Input prompt: summarize the text below:\\n\\ntext = \\\"Amazon Comprehend uses natural language processing (NLP) to extract insights about the content of documents. It develops insights by recognizing the entities, key phrases, language, sentiments, and other common elements in a document. Use Amazon Comprehend to create new products based on understanding the structure of documents. For example, using Amazon Comprehend you can search social networking feeds for mentions of products or scan an entire document repository for key phrases.\\\"',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69531651-8875-4379-b605-a2034fd48e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QA Bot\n",
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='[user] Who are some of the best writers of English literature?\\n[bot] William Shakespeare, Charles Dickens, Oscar Wilde, Jane Austen, and William Blake\\n[user] Can you tell me more about Wilde?\\n[bot] He was a poet, painter, and engraver.\\n[user] Where was he born, and when?\\n[bot] Blake was born in London in 1757.\\n[user] What is the most famous book by him? what is the rationale behind it?\\n[bot]',\n",
    "  # prompt='[user] Who are some of the best writers of English literature?\\n\n",
    "  #         [bot] William Shakespeare, Charles Dickens, Oscar Wilde, Jane Austen, and William Blake\\n\n",
    "  #         [user] Can you tell me more about Wilde?\\n\n",
    "  #         [bot] He was a poet, painter, and engraver.\\n\n",
    "  #         [user] Where was he born, and when?\\n\n",
    "  #         [bot] Blake was born in London in 1757.\\n\n",
    "  #         [user] What is the most famous book by him? what is the rationale behind it?\\n\n",
    "  #         [bot]',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c0711-fcbe-4ff0-9ca0-96f840c624a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reasoning Engine\n",
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Sample Prompt: \\nCan Geoffrey Hinton have a conversation with George Washington? \\nGive Yes or No Answer\\nGive the reason behind it',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0daa7-bdd4-4ce8-9234-4e94228c5a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reasoning Engine\n",
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Sample Prompt: \\nCan Sachin can win Cricket World Cup 2023?\\nGive Yes or No Answer\\nGive the reason behind it',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98731705-0132-4c15-8336-5ce16774d456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Classification:  Tweet: \\\"I hate it when my phone battery dies.”: Sentiment: Negative\\nTweet: \\\"My day has been great”: Sentiment: Positive\\nTweet: \\\"This is the link to the article”: Sentiment: Neutral\\nTweet: \\\"This new music video was incredibile but  its not my favourite” Sentiment:',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59280665-b968-4471-a97e-2aa57c174003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Below is SageMaker Low-code ML FAQ:\\n\\n##\\nQ: Will my data (from inference or training) be used or shared to update the base model that is offered to customers using Amazon SageMaker JumpStart?\\nNo. Your inference and training data will not be used nor shared to update or train the base model that SageMaker JumpStart surfaces to customers.\\n\\nQ: Can I see the model weights and scripts of proprietary models in preview with Amazon SageMaker JumpStart?\\nNo. Proprietary models do not allow customers to view model weights and scripts.\\n\\nQ: Which open-source models are supported with Amazon SageMaker JumpStart?\\nAmazon SageMaker JumpStart includes 150+ pre-trained open-source models from PyTorch Hub and TensorFlow Hub. For vision tasks such as image classification and object detection, you can use models such as ResNet, MobileNet, and Single-Shot Detector (SSD). For text tasks such as sentence classification, text classification, and question answering, you can use models such as BERT, RoBERTa, and DistilBERT.\\n\\nQ: What solutions come pre-built with Amazon SageMaker JumpStart?\\nSageMaker JumpStart includes solutions that are preconfigured with all necessary AWS services to launch a solution into production. Solutions are fully customizable so you can easily modify them to fit your specific use case and dataset. You can use solutions for over 15 use cases including demand forecasting, fraud detection, and predictive maintenance, and readily deploy solutions with just a few clicks. For more information about all solutions available, visit the SageMaker getting started page. \\n\\nQ: What built-in algorithms are supported in Amazon SageMaker Autopilot?\\nAmazon SageMaker Autopilot supports 2 built-in algorithms: XGBoost and Linear Learner.\\n\\nQ: Can I stop an Amazon SageMaker Autopilot job manually?\\nYes. You can stop a job at any time. When an Amazon SageMaker Autopilot job is stopped, all ongoing trials will be stopped and no new trial will be started.\\n##\\n\\nCreate a multiple choice quiz on the topic of SageMaker Low-code ML FAQ consisting of 4 questions. Each question should have 4 options. Also include the correct answer for each question using the starting string \\'Correct Answer:` and Explanation of Answer using the Starting String \\'Explaination\\'',\n",
    "  max_tokens=800,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee5036-11bb-4d02-99c5-44be9e5c85f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chain of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43cbde-abb0-4915-ac06-7546144d0f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='I went to the market and bought 10 apples. I gave 2 apples\\nto the neighbor and 2 to the repairman. I then went and\\nbought 5 more apples and ate 1. How many apples did I\\nremain with?\\n\\nLet\\'s think step by step',\n",
    "  max_tokens=300,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c522fc-47b7-43ce-a48b-553fff93dbe8",
   "metadata": {},
   "source": [
    "## Instruct to Build a Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e33e81-f2c9-4634-b0cd-205fd9a57117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(api_key) # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Create a Serverless Application Code using AWS Cloud Development Kit (CDK) Python using below Steps \\n1) Create a S3 Bucket name \\\"gen-ai-workshop-blr-s3bucket\\\"\\n2) Create a DynamoDB table \\\"gen-ai-workshop-blr-table\\\"\\n3) Create a Event driven Lambda function read the S3 Bucket when upload any new file and parse the json file and load to DynamoDB table \\\"gen-ai-workshop-blr-table\\\"\\n4) Create a Simple JSON file and upload to  \\\"gen-ai-workshop-blr-s3bucket\\\" ',\n",
    "  max_tokens=3008,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a123d-46a2-420f-b93b-b018c69768ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, May  7 2023, 23:32:44) \n[Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
